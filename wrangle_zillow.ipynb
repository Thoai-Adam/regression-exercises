{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e9010c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosave disabled\n"
     ]
    }
   ],
   "source": [
    "%autosave 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "747692fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from env import get_connection\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "338f41ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_sql(query, url)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[0;32m---> 13\u001b[0m \u001b[43mdf\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "def acquire_data():\n",
    "    url = get_connection('zillow')\n",
    "    query = '''\n",
    "            SELECT bedroomcnt, bathroomcnt, calculatedfinishedsquarefeet,\n",
    "                   taxvaluedollarcnt, yearbuilt, taxamount, fips\n",
    "            FROM properties_2017\n",
    "            JOIN propertylandusetype\n",
    "                ON properties_2017.propertylandusetypeid = propertylandusetype.propertylandusetypeid\n",
    "            WHERE propertylandusetype.propertylandusedesc = 'Single Family Residential';\n",
    "            '''\n",
    "    df = pd.read_sql(query, url)\n",
    "    return df\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b9ceed9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m acquire_data(\u001b[43mdf\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "acquire_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9141a055",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6328e2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb3e114",
   "metadata": {},
   "source": [
    "since bedroomcnt and bathroomcnt and taxvaluedollarcnt has the least nulls values, I decide dropping it would not affect the data. With the other features containing high null values, I will have to impute those with the mean of all observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bab64a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def clean_and_impute_data(df):\n",
    "    # Drop rows with null values in specified columns\n",
    "    columns_to_drop_null = ['bedroomcnt', 'bathroomcnt', 'taxvaluedollarcnt']\n",
    "    df.dropna(subset=columns_to_drop_null, inplace=True)\n",
    "    \n",
    "    # Impute null values with means for specified columns\n",
    "    columns_to_impute = ['calculatedfinishedsquarefeet', 'yearbuilt', 'taxamount']\n",
    "    for column in columns_to_impute:\n",
    "        mean_value = df[column].mean()\n",
    "        df[column].fillna(mean_value, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "cleaned_df = clean_and_impute_data(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3922ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape  #a few observations has been dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e584d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dbb885",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info() #everything is float so it is good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b738cdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 3))\n",
    "\n",
    "# List of columns\n",
    "cols = ['bedroomcnt', 'bathroomcnt', 'calculatedfinishedsquarefeet', 'taxvaluedollarcnt', 'yearbuilt', 'taxamount', 'fips']\n",
    "\n",
    "for i, col in enumerate(cols):\n",
    "\n",
    "    # i starts at 0, but plot nos should start at 1\n",
    "    plot_number = i + 1 \n",
    "\n",
    "    # Create subplot.\n",
    "    plt.subplot(1,10, plot_number)\n",
    "\n",
    "    # Title with column name.\n",
    "    plt.title(col)\n",
    "\n",
    "    # Display histogram for column.\n",
    "    df[col].hist(bins=5)\n",
    "\n",
    "    # Hide gridlines.\n",
    "    plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece5ae47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize=(10,14))\n",
    "\n",
    "# Create boxplots for all but student_id.\n",
    "sns.boxplot(data=df.drop(columns=['fips']))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb1d48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from env import get_connection  # Make sure these variables are defined in env.py\n",
    "\n",
    "\n",
    "\n",
    "def get_zillow_data():\n",
    "    filename = \"zillow.csv\"\n",
    "\n",
    "    if os.path.isfile(filename):\n",
    "        return pd.read_csv(filename, index_col=0)\n",
    "    else:\n",
    "        # Create the url\n",
    "        url = get_connection('zillow')\n",
    "\n",
    "        # Read the SQL query into a dataframe\n",
    "        query = '''\n",
    "                SELECT bedroomcnt, bathroomcnt, calculatedfinishedsquarefeet,\n",
    "                       taxvaluedollarcnt, yearbuilt, taxamount, fips\n",
    "                FROM properties_2017\n",
    "                JOIN propertylandusetype\n",
    "                    ON properties_2017.propertylandusetypeid = propertylandusetype.propertylandusetypeid\n",
    "                WHERE propertylandusetype.propertylandusedesc = 'Single Family Residential';\n",
    "                '''\n",
    "        df = pd.read_sql(query, url)\n",
    "\n",
    "        # Write the dataframe to disk for later. Called \"caching\" the data for later.\n",
    "        df.to_csv(filename)\n",
    "\n",
    "        # Return the dataframe to the calling code\n",
    "        return df\n",
    "\n",
    "def wrangle_zillow():\n",
    "    '''\n",
    "    Read Zillow data from database, drop rows with NaN values,\n",
    "    convert all columns to int64 data types, and return cleaned DataFrame.\n",
    "    '''\n",
    "    zillow = get_zillow_data()\n",
    "\n",
    "    # Drop all rows with NaN values.\n",
    "    df = zillow.dropna()\n",
    "\n",
    "    # Convert all columns to int64 data types.\n",
    "    df = df.astype('int')\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f6dfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = wrangle_zillow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a47b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3002372d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#only fit scaling object to train data set\n",
    "seed = 42\n",
    "\n",
    "train, val_test = train_test_split(df, train_size = 0.8,\n",
    "                                  random_state = seed)\n",
    "\n",
    "val, test = train_test_split(val_test, train_size = 0.5,\n",
    "                           random_state = seed)\n",
    "\n",
    "train.shape, val.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78d09b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252bc885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed3f80f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34cafdbf",
   "metadata": {},
   "source": [
    "\n",
    "        # Columns to scale\n",
    "        cols_to_scale = ['bedroomcnt', 'bathroomcnt', 'calculatedfinishedsquarefeet', 'taxvaluedollarcnt', 'yearbuilt', 'taxamount']\n",
    "\n",
    "        # Fit scaler on training data and transform all data splits\n",
    "        StandardScaler.fit(df_train[cols_to_scale])\n",
    "        df_train[cols_to_scale] = scaler.transform(df_train[cols_to_scale])\n",
    "        df_validate[cols_to_scale] = scaler.transform(df_validate[cols_to_scale])\n",
    "        df_test[cols_to_scale] = scaler.transform(df_test[cols_to_scale])\n",
    "\n",
    "        return df_train, df_validate, df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239157cf",
   "metadata": {},
   "source": [
    "def prepare_zillow_data():\n",
    "    # Acquire and clean data\n",
    "    df = acquire_data()\n",
    "    df_cleaned = clean_and_impute_data(df)\n",
    "\n",
    "    # Visualize cleaned data\n",
    "    visualize_data(df_cleaned)\n",
    "\n",
    "    # Split data into train, validate, and test sets\n",
    "\n",
    "    # Apply scaling using MinMaxScaler\n",
    "    df_train_scaled, df_validate_scaled, df_test_scaled = apply_scaling(df_train, df_validate, df_test, MinMaxScaler())\n",
    "\n",
    "    return df_train_scaled, df_validate_scaled, df_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d7a246",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
